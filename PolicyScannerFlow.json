{
    "name":"PolicyScannerFlow",
    "description":"Crafting Dialogues that Drive Business Success.",
    "webhook":false,
    "user_id":"cb607683-5976-47c5-a2b0-d0fe3fba4c70",
    "endpoint_name":null,
    "tags":null,
    "folder_id":"8e7ca8c2-c12d-4faa-ae08-a5fa5349c415",
    "gradient":null,
    "id":"ba8d1886-8f1f-45a9-a778-5526ba589676",
    "is_component":false,
    "data":{
       "nodes":[
          {
             "id":"OllamaModel-kmzJQ",
             "type":"genericNode",
             "position":{
                "x":436.66554573451424,
                "y":74.96798335938385
             },
             "data":{
                "node":{
                   "template":{
                      "_type":"Component",
                      "output_parser":{
                         "trace_as_metadata":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"output_parser",
                         "value":"",
                         "display_name":"Output Parser",
                         "advanced":true,
                         "input_types":[
                            "OutputParser"
                         ],
                         "dynamic":false,
                         "info":"The parser to use to parse the output of the model",
                         "title_case":false,
                         "type":"other",
                         "_input_type":"HandleInput"
                      },
                      "base_url":{
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"base_url",
                         "value":"http://localhost:11434",
                         "display_name":"Base URL",
                         "advanced":false,
                         "dynamic":false,
                         "info":"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"StrInput"
                      },
                      "code":{
                         "type":"code",
                         "required":true,
                         "placeholder":"",
                         "list":false,
                         "show":true,
                         "multiline":true,
                         "value":"from typing import Any\nfrom urllib.parse import urljoin\n\nimport httpx\nfrom langchain_ollama import ChatOllama\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, StrInput\n\n\nclass ChatOllamaComponent(LCModelComponent):\n    display_name = \"Ollama\"\n    description = \"Generate text using Ollama Local LLMs.\"\n    icon = \"Ollama\"\n    name = \"OllamaModel\"\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None):\n        if field_name == \"mirostat\":\n            if field_value == \"Disabled\":\n                build_config[\"mirostat_eta\"][\"advanced\"] = True\n                build_config[\"mirostat_tau\"][\"advanced\"] = True\n                build_config[\"mirostat_eta\"][\"value\"] = None\n                build_config[\"mirostat_tau\"][\"value\"] = None\n\n            else:\n                build_config[\"mirostat_eta\"][\"advanced\"] = False\n                build_config[\"mirostat_tau\"][\"advanced\"] = False\n\n                if field_value == \"Mirostat 2.0\":\n                    build_config[\"mirostat_eta\"][\"value\"] = 0.2\n                    build_config[\"mirostat_tau\"][\"value\"] = 10\n                else:\n                    build_config[\"mirostat_eta\"][\"value\"] = 0.1\n                    build_config[\"mirostat_tau\"][\"value\"] = 5\n\n        if field_name == \"model_name\":\n            base_url_dict = build_config.get(\"base_url\", {})\n            base_url_load_from_db = base_url_dict.get(\"load_from_db\", False)\n            base_url_value = base_url_dict.get(\"value\")\n            if base_url_load_from_db:\n                base_url_value = self.variables(base_url_value, field_name)\n            elif not base_url_value:\n                base_url_value = \"http://localhost:11434\"\n            build_config[\"model_name\"][\"options\"] = self.get_model(base_url_value)\n        if field_name == \"keep_alive_flag\":\n            if field_value == \"Keep\":\n                build_config[\"keep_alive\"][\"value\"] = \"-1\"\n                build_config[\"keep_alive\"][\"advanced\"] = True\n            elif field_value == \"Immediately\":\n                build_config[\"keep_alive\"][\"value\"] = \"0\"\n                build_config[\"keep_alive\"][\"advanced\"] = True\n            else:\n                build_config[\"keep_alive\"][\"advanced\"] = False\n\n        return build_config\n\n    def get_model(self, base_url_value: str) -> list[str]:\n        try:\n            url = urljoin(base_url_value, \"/api/tags\")\n            with httpx.Client() as client:\n                response = client.get(url)\n                response.raise_for_status()\n                data = response.json()\n\n                return [model[\"name\"] for model in data.get(\"models\", [])]\n        except Exception as e:\n            msg = \"Could not retrieve models. Please, make sure Ollama is running.\"\n            raise ValueError(msg) from e\n\n    inputs = [\n        StrInput(\n            name=\"base_url\",\n            display_name=\"Base URL\",\n            info=\"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\n            value=\"http://localhost:11434\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            value=\"llama3.1\",\n            info=\"Refer to https://ollama.com/library for more models.\",\n            refresh_button=True,\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.2,\n            info=\"Controls the creativity of model responses.\",\n        ),\n        StrInput(\n            name=\"format\", display_name=\"Format\", info=\"Specify the format of the output (e.g., json).\", advanced=True\n        ),\n        DictInput(name=\"metadata\", display_name=\"Metadata\", info=\"Metadata to add to the run trace.\", advanced=True),\n        DropdownInput(\n            name=\"mirostat\",\n            display_name=\"Mirostat\",\n            options=[\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n            info=\"Enable/disable Mirostat sampling for controlling perplexity.\",\n            value=\"Disabled\",\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        FloatInput(\n            name=\"mirostat_eta\",\n            display_name=\"Mirostat Eta\",\n            info=\"Learning rate for Mirostat algorithm. (Default: 0.1)\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"mirostat_tau\",\n            display_name=\"Mirostat Tau\",\n            info=\"Controls the balance between coherence and diversity of the output. (Default: 5.0)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"num_ctx\",\n            display_name=\"Context Window Size\",\n            info=\"Size of the context window for generating tokens. (Default: 2048)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"num_gpu\",\n            display_name=\"Number of GPUs\",\n            info=\"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"num_thread\",\n            display_name=\"Number of Threads\",\n            info=\"Number of threads to use during computation. (Default: detected for optimal performance)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"repeat_last_n\",\n            display_name=\"Repeat Last N\",\n            info=\"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"repeat_penalty\",\n            display_name=\"Repeat Penalty\",\n            info=\"Penalty for repetitions in generated text. (Default: 1.1)\",\n            advanced=True,\n        ),\n        FloatInput(name=\"tfs_z\", display_name=\"TFS Z\", info=\"Tail free sampling value. (Default: 1)\", advanced=True),\n        IntInput(name=\"timeout\", display_name=\"Timeout\", info=\"Timeout for the request stream.\", advanced=True),\n        IntInput(\n            name=\"top_k\", display_name=\"Top K\", info=\"Limits token selection to top K. (Default: 40)\", advanced=True\n        ),\n        FloatInput(name=\"top_p\", display_name=\"Top P\", info=\"Works together with top-k. (Default: 0.9)\", advanced=True),\n        BoolInput(name=\"verbose\", display_name=\"Verbose\", info=\"Whether to print out response text.\", advanced=True),\n        StrInput(\n            name=\"tags\",\n            display_name=\"Tags\",\n            info=\"Comma-separated list of tags to add to the run trace.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"stop_tokens\",\n            display_name=\"Stop Tokens\",\n            info=\"Comma-separated list of tokens to signal the model to stop generating text.\",\n            advanced=True,\n        ),\n        StrInput(name=\"system\", display_name=\"System\", info=\"System to use for generating text.\", advanced=True),\n        StrInput(name=\"template\", display_name=\"Template\", info=\"Template to use for generating text.\", advanced=True),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n        *LCModelComponent._base_inputs,\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # Mapping mirostat settings to their corresponding values\n        mirostat_options = {\"Mirostat\": 1, \"Mirostat 2.0\": 2}\n\n        # Default to 0 for 'Disabled'\n        mirostat_value = mirostat_options.get(self.mirostat, 0)\n\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\n        if mirostat_value == 0:\n            mirostat_eta = None\n            mirostat_tau = None\n        else:\n            mirostat_eta = self.mirostat_eta\n            mirostat_tau = self.mirostat_tau\n\n        # Mapping system settings to their corresponding values\n        llm_params = {\n            \"base_url\": self.base_url,\n            \"model\": self.model_name,\n            \"mirostat\": mirostat_value,\n            \"format\": self.format,\n            \"metadata\": self.metadata,\n            \"tags\": self.tags.split(\",\") if self.tags else None,\n            \"mirostat_eta\": mirostat_eta,\n            \"mirostat_tau\": mirostat_tau,\n            \"num_ctx\": self.num_ctx or None,\n            \"num_gpu\": self.num_gpu or None,\n            \"num_thread\": self.num_thread or None,\n            \"repeat_last_n\": self.repeat_last_n or None,\n            \"repeat_penalty\": self.repeat_penalty or None,\n            \"temperature\": self.temperature or None,\n            \"stop\": self.stop_tokens.split(\",\") if self.stop_tokens else None,\n            \"system\": self.system,\n            \"template\": self.template,\n            \"tfs_z\": self.tfs_z or None,\n            \"timeout\": self.timeout or None,\n            \"top_k\": self.top_k or None,\n            \"top_p\": self.top_p or None,\n            \"verbose\": self.verbose,\n        }\n\n        # Remove parameters with None values\n        llm_params = {k: v for k, v in llm_params.items() if v is not None}\n\n        try:\n            output = ChatOllama(**llm_params)\n        except Exception as e:\n            msg = \"Could not initialize Ollama LLM.\"\n            raise ValueError(msg) from e\n\n        return output\n",
                         "fileTypes":[
                            
                         ],
                         "file_path":"",
                         "password":false,
                         "name":"code",
                         "advanced":true,
                         "dynamic":true,
                         "info":"",
                         "load_from_db":false,
                         "title_case":false
                      },
                      "format":{
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"format",
                         "value":"",
                         "display_name":"Format",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Specify the format of the output (e.g., json).",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"StrInput"
                      },
                      "input_value":{
                         "trace_as_input":true,
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"input_value",
                         "value":"",
                         "display_name":"Input",
                         "advanced":false,
                         "input_types":[
                            "Message"
                         ],
                         "dynamic":false,
                         "info":"",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"MessageInput"
                      },
                      "metadata":{
                         "trace_as_input":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"metadata",
                         "value":{
                            
                         },
                         "display_name":"Metadata",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Metadata to add to the run trace.",
                         "title_case":false,
                         "type":"dict",
                         "_input_type":"DictInput"
                      },
                      "mirostat":{
                         "tool_mode":false,
                         "trace_as_metadata":true,
                         "options":[
                            "Disabled",
                            "Mirostat",
                            "Mirostat 2.0"
                         ],
                         "combobox":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"mirostat",
                         "value":"Disabled",
                         "display_name":"Mirostat",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Enable/disable Mirostat sampling for controlling perplexity.",
                         "real_time_refresh":true,
                         "title_case":false,
                         "type":"str",
                         "_input_type":"DropdownInput"
                      },
                      "mirostat_eta":{
                         "trace_as_metadata":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"mirostat_eta",
                         "value":"",
                         "display_name":"Mirostat Eta",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Learning rate for Mirostat algorithm. (Default: 0.1)",
                         "title_case":false,
                         "type":"float",
                         "_input_type":"FloatInput"
                      },
                      "mirostat_tau":{
                         "trace_as_metadata":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"mirostat_tau",
                         "value":"",
                         "display_name":"Mirostat Tau",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Controls the balance between coherence and diversity of the output. (Default: 5.0)",
                         "title_case":false,
                         "type":"float",
                         "_input_type":"FloatInput"
                      },
                      "model_name":{
                         "tool_mode":false,
                         "trace_as_metadata":true,
                         "options":[
                            "llama3.2:latest"
                         ],
                         "combobox":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"model_name",
                         "value":"llama3.2:latest",
                         "display_name":"Model Name",
                         "advanced":false,
                         "dynamic":false,
                         "info":"Refer to https://ollama.com/library for more models.",
                         "refresh_button":true,
                         "title_case":false,
                         "type":"str",
                         "_input_type":"DropdownInput"
                      },
                      "num_ctx":{
                         "trace_as_metadata":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"num_ctx",
                         "value":"",
                         "display_name":"Context Window Size",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Size of the context window for generating tokens. (Default: 2048)",
                         "title_case":false,
                         "type":"int",
                         "_input_type":"IntInput"
                      },
                      "num_gpu":{
                         "trace_as_metadata":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"num_gpu",
                         "value":"",
                         "display_name":"Number of GPUs",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)",
                         "title_case":false,
                         "type":"int",
                         "_input_type":"IntInput"
                      },
                      "num_thread":{
                         "trace_as_metadata":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"num_thread",
                         "value":"",
                         "display_name":"Number of Threads",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Number of threads to use during computation. (Default: detected for optimal performance)",
                         "title_case":false,
                         "type":"int",
                         "_input_type":"IntInput"
                      },
                      "repeat_last_n":{
                         "trace_as_metadata":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"repeat_last_n",
                         "value":"",
                         "display_name":"Repeat Last N",
                         "advanced":true,
                         "dynamic":false,
                         "info":"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)",
                         "title_case":false,
                         "type":"int",
                         "_input_type":"IntInput"
                      },
                      "repeat_penalty":{
                         "trace_as_metadata":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"repeat_penalty",
                         "value":"",
                         "display_name":"Repeat Penalty",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Penalty for repetitions in generated text. (Default: 1.1)",
                         "title_case":false,
                         "type":"float",
                         "_input_type":"FloatInput"
                      },
                      "stop_tokens":{
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"stop_tokens",
                         "value":"",
                         "display_name":"Stop Tokens",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Comma-separated list of tokens to signal the model to stop generating text.",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"StrInput"
                      },
                      "stream":{
                         "trace_as_metadata":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"stream",
                         "value":false,
                         "display_name":"Stream",
                         "advanced":false,
                         "dynamic":false,
                         "info":"Stream the response from the model. Streaming works only in Chat.",
                         "title_case":false,
                         "type":"bool",
                         "_input_type":"BoolInput"
                      },
                      "system":{
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"system",
                         "value":"",
                         "display_name":"System",
                         "advanced":true,
                         "dynamic":false,
                         "info":"System to use for generating text.",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"StrInput"
                      },
                      "system_message":{
                         "tool_mode":false,
                         "trace_as_input":true,
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"system_message",
                         "value":"",
                         "display_name":"System Message",
                         "advanced":false,
                         "input_types":[
                            "Message"
                         ],
                         "dynamic":false,
                         "info":"System message to pass to the model.",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"MessageTextInput"
                      },
                      "tags":{
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"tags",
                         "value":"",
                         "display_name":"Tags",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Comma-separated list of tags to add to the run trace.",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"StrInput"
                      },
                      "temperature":{
                         "trace_as_metadata":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"temperature",
                         "value":0.2,
                         "display_name":"Temperature",
                         "advanced":false,
                         "dynamic":false,
                         "info":"Controls the creativity of model responses.",
                         "title_case":false,
                         "type":"float",
                         "_input_type":"FloatInput"
                      },
                      "template":{
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"template",
                         "value":"",
                         "display_name":"Template",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Template to use for generating text.",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"StrInput"
                      },
                      "tfs_z":{
                         "trace_as_metadata":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"tfs_z",
                         "value":"",
                         "display_name":"TFS Z",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Tail free sampling value. (Default: 1)",
                         "title_case":false,
                         "type":"float",
                         "_input_type":"FloatInput"
                      },
                      "timeout":{
                         "trace_as_metadata":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"timeout",
                         "value":"",
                         "display_name":"Timeout",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Timeout for the request stream.",
                         "title_case":false,
                         "type":"int",
                         "_input_type":"IntInput"
                      },
                      "top_k":{
                         "trace_as_metadata":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"top_k",
                         "value":"",
                         "display_name":"Top K",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Limits token selection to top K. (Default: 40)",
                         "title_case":false,
                         "type":"int",
                         "_input_type":"IntInput"
                      },
                      "top_p":{
                         "trace_as_metadata":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"top_p",
                         "value":"",
                         "display_name":"Top P",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Works together with top-k. (Default: 0.9)",
                         "title_case":false,
                         "type":"float",
                         "_input_type":"FloatInput"
                      },
                      "verbose":{
                         "trace_as_metadata":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"verbose",
                         "value":false,
                         "display_name":"Verbose",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Whether to print out response text.",
                         "title_case":false,
                         "type":"bool",
                         "_input_type":"BoolInput"
                      }
                   },
                   "description":"Generate text using Ollama Local LLMs.",
                   "icon":"Ollama",
                   "base_classes":[
                      "LanguageModel",
                      "Message"
                   ],
                   "display_name":"Ollama",
                   "documentation":"",
                   "custom_fields":{
                      
                   },
                   "output_types":[
                      
                   ],
                   "pinned":false,
                   "conditional_paths":[
                      
                   ],
                   "frozen":false,
                   "outputs":[
                      {
                         "types":[
                            "Message"
                         ],
                         "selected":"Message",
                         "name":"text_output",
                         "hidden":false,
                         "display_name":"Text",
                         "method":"text_response",
                         "value":"__UNDEFINED__",
                         "cache":true,
                         "required_inputs":[
                            
                         ]
                      },
                      {
                         "types":[
                            "LanguageModel"
                         ],
                         "selected":"LanguageModel",
                         "name":"model_output",
                         "hidden":false,
                         "display_name":"Language Model",
                         "method":"build_model",
                         "value":"__UNDEFINED__",
                         "cache":true,
                         "required_inputs":[
                            
                         ]
                      }
                   ],
                   "field_order":[
                      "base_url",
                      "model_name",
                      "temperature",
                      "format",
                      "metadata",
                      "mirostat",
                      "mirostat_eta",
                      "mirostat_tau",
                      "num_ctx",
                      "num_gpu",
                      "num_thread",
                      "repeat_last_n",
                      "repeat_penalty",
                      "tfs_z",
                      "timeout",
                      "top_k",
                      "top_p",
                      "verbose",
                      "tags",
                      "stop_tokens",
                      "system",
                      "template",
                      "output_parser",
                      "input_value",
                      "system_message",
                      "stream"
                   ],
                   "beta":false,
                   "legacy":false,
                   "edited":false,
                   "metadata":{
                      
                   },
                   "tool_mode":false,
                   "lf_version":"1.1.0"
                },
                "type":"OllamaModel",
                "id":"OllamaModel-kmzJQ"
             },
             "selected":false,
             "width":320,
             "height":672,
             "positionAbsolute":{
                "x":436.66554573451424,
                "y":74.96798335938385
             },
             "dragging":false
          },
          {
             "id":"CustomComponent-Kwa0O",
             "type":"genericNode",
             "position":{
                "x":833.2235258216726,
                "y":221.01467116982798
             },
             "data":{
                "node":{
                   "template":{
                      "_type":"Component",
                      "code":{
                         "type":"code",
                         "required":true,
                         "placeholder":"",
                         "list":false,
                         "show":true,
                         "multiline":true,
                         "value":"from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nimport json\n\nclass jsonParser(Component):\n    display_name = \"JSON Parser\"\n    description = \"Convert raw text into JSON template\"\n    icon = \"braces\"\n    name = \"jsonParser\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Input Value\",\n            info=\"Raw text input\",\n            value=\" \",\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Message:\n        result_string = convert_bullets_to_json(self.input_value)\n        self.status = result_string\n        return Message(text=result_string)\n\n\n\ndef convert_bullets_to_json(text):\n    # Split the text by bullet points\n    lines = text.strip().split('\\n')\n    \n    # Extract bullet points (skipping any introductory paragraph)\n    bullet_points = []\n    for line in lines:\n        line = line.strip()\n        if line.startswith('â€¢') or line.startswith('-') or line.startswith('*'):\n            # Remove the bullet character and any leading/trailing whitespace\n            content = line[1:].strip()\n            bullet_points.append(content)\n    \n    # Create a JSON structure with a status field that indicates success or issues\n    result = {\n        \"status\": \"success\" if bullet_points else \"warning\",\n        \"message\": \"\",\n        \"points\": bullet_points\n    }\n    \n    # Add appropriate message based on number of points found\n    if not bullet_points:\n        result[\"message\"] = \"No bullet points found in the text.\"\n    elif len(bullet_points) < 3:\n        result[\"message\"] = f\"Expected 3 bullet points, but only found {len(bullet_points)}.\"\n    \n    # Return formatted JSON\n    return json.dumps(result, indent=2)\n",
                         "fileTypes":[
                            
                         ],
                         "file_path":"",
                         "password":false,
                         "name":"code",
                         "advanced":true,
                         "dynamic":true,
                         "info":"",
                         "load_from_db":false,
                         "title_case":false
                      },
                      "input_value":{
                         "tool_mode":true,
                         "trace_as_input":true,
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"input_value",
                         "value":"",
                         "display_name":"Input Value",
                         "advanced":false,
                         "input_types":[
                            "Message"
                         ],
                         "dynamic":false,
                         "info":"Raw text input",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"MessageTextInput"
                      }
                   },
                   "description":"Convert raw text into JSON template",
                   "icon":"braces",
                   "base_classes":[
                      "Message"
                   ],
                   "display_name":"JSON Parser",
                   "documentation":"",
                   "custom_fields":{
                      
                   },
                   "output_types":[
                      
                   ],
                   "pinned":false,
                   "conditional_paths":[
                      
                   ],
                   "frozen":false,
                   "outputs":[
                      {
                         "types":[
                            "Message"
                         ],
                         "selected":"Message",
                         "name":"output",
                         "display_name":"Output",
                         "method":"build_output",
                         "value":"__UNDEFINED__",
                         "cache":true
                      }
                   ],
                   "field_order":[
                      "input_value"
                   ],
                   "beta":false,
                   "legacy":false,
                   "edited":true,
                   "metadata":{
                      
                   },
                   "tool_mode":false,
                   "lf_version":"1.1.0"
                },
                "type":"jsonParser",
                "id":"CustomComponent-Kwa0O"
             },
             "selected":false,
             "width":320,
             "height":233,
             "positionAbsolute":{
                "x":833.2235258216726,
                "y":221.01467116982798
             },
             "dragging":false
          },
          {
             "id":"ChatOutput-2w5Rb",
             "type":"genericNode",
             "position":{
                "x":1229.8749792958401,
                "y":48.29337122954013
             },
             "data":{
                "node":{
                   "template":{
                      "_type":"Component",
                      "background_color":{
                         "tool_mode":false,
                         "trace_as_input":true,
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"background_color",
                         "value":"",
                         "display_name":"Background Color",
                         "advanced":true,
                         "input_types":[
                            "Message"
                         ],
                         "dynamic":false,
                         "info":"The background color of the icon.",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"MessageTextInput"
                      },
                      "chat_icon":{
                         "tool_mode":false,
                         "trace_as_input":true,
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"chat_icon",
                         "value":"",
                         "display_name":"Icon",
                         "advanced":true,
                         "input_types":[
                            "Message"
                         ],
                         "dynamic":false,
                         "info":"The icon of the message.",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"MessageTextInput"
                      },
                      "code":{
                         "type":"code",
                         "required":true,
                         "placeholder":"",
                         "list":false,
                         "show":true,
                         "multiline":true,
                         "value":"from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                         "fileTypes":[
                            
                         ],
                         "file_path":"",
                         "password":false,
                         "name":"code",
                         "advanced":true,
                         "dynamic":true,
                         "info":"",
                         "load_from_db":false,
                         "title_case":false
                      },
                      "data_template":{
                         "tool_mode":false,
                         "trace_as_input":true,
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"data_template",
                         "value":"{text}",
                         "display_name":"Data Template",
                         "advanced":true,
                         "input_types":[
                            "Message"
                         ],
                         "dynamic":false,
                         "info":"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"MessageTextInput"
                      },
                      "input_value":{
                         "trace_as_input":true,
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"input_value",
                         "value":"",
                         "display_name":"Text",
                         "advanced":false,
                         "input_types":[
                            "Message"
                         ],
                         "dynamic":false,
                         "info":"Message to be passed as output.",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"MessageInput"
                      },
                      "sender":{
                         "tool_mode":false,
                         "trace_as_metadata":true,
                         "options":[
                            "Machine",
                            "User"
                         ],
                         "combobox":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"sender",
                         "value":"Machine",
                         "display_name":"Sender Type",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Type of sender.",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"DropdownInput"
                      },
                      "sender_name":{
                         "tool_mode":false,
                         "trace_as_input":true,
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"sender_name",
                         "value":"AI",
                         "display_name":"Sender Name",
                         "advanced":true,
                         "input_types":[
                            "Message"
                         ],
                         "dynamic":false,
                         "info":"Name of the sender.",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"MessageTextInput"
                      },
                      "session_id":{
                         "tool_mode":false,
                         "trace_as_input":true,
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"session_id",
                         "value":"",
                         "display_name":"Session ID",
                         "advanced":true,
                         "input_types":[
                            "Message"
                         ],
                         "dynamic":false,
                         "info":"The session ID of the chat. If empty, the current session ID parameter will be used.",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"MessageTextInput"
                      },
                      "should_store_message":{
                         "trace_as_metadata":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"should_store_message",
                         "value":true,
                         "display_name":"Store Messages",
                         "advanced":true,
                         "dynamic":false,
                         "info":"Store the message in the history.",
                         "title_case":false,
                         "type":"bool",
                         "_input_type":"BoolInput"
                      },
                      "text_color":{
                         "tool_mode":false,
                         "trace_as_input":true,
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"text_color",
                         "value":"",
                         "display_name":"Text Color",
                         "advanced":true,
                         "input_types":[
                            "Message"
                         ],
                         "dynamic":false,
                         "info":"The text color of the name",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"MessageTextInput"
                      }
                   },
                   "description":"Display a chat message in the Playground.",
                   "icon":"MessagesSquare",
                   "base_classes":[
                      "Message"
                   ],
                   "display_name":"Chat Output",
                   "documentation":"",
                   "custom_fields":{
                      
                   },
                   "output_types":[
                      
                   ],
                   "pinned":false,
                   "conditional_paths":[
                      
                   ],
                   "frozen":false,
                   "outputs":[
                      {
                         "types":[
                            "Message"
                         ],
                         "selected":"Message",
                         "name":"message",
                         "display_name":"Message",
                         "method":"message_response",
                         "value":"__UNDEFINED__",
                         "cache":true
                      }
                   ],
                   "field_order":[
                      "input_value",
                      "should_store_message",
                      "sender",
                      "sender_name",
                      "session_id",
                      "data_template",
                      "background_color",
                      "chat_icon",
                      "text_color"
                   ],
                   "beta":false,
                   "legacy":false,
                   "edited":false,
                   "metadata":{
                      
                   },
                   "tool_mode":false,
                   "lf_version":"1.1.0"
                },
                "type":"ChatOutput",
                "id":"ChatOutput-2w5Rb"
             },
             "selected":false,
             "width":320,
             "height":233,
             "positionAbsolute":{
                "x":1229.8749792958401,
                "y":48.29337122954013
             },
             "dragging":false
          },
          {
             "id":"TextOutput-C9FWZ",
             "type":"genericNode",
             "position":{
                "x":1258.3528285539594,
                "y":430.16605766087207
             },
             "data":{
                "node":{
                   "template":{
                      "_type":"Component",
                      "code":{
                         "type":"code",
                         "required":true,
                         "placeholder":"",
                         "list":false,
                         "show":true,
                         "multiline":true,
                         "value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n",
                         "fileTypes":[
                            
                         ],
                         "file_path":"",
                         "password":false,
                         "name":"code",
                         "advanced":true,
                         "dynamic":true,
                         "info":"",
                         "load_from_db":false,
                         "title_case":false
                      },
                      "input_value":{
                         "tool_mode":false,
                         "trace_as_input":true,
                         "multiline":true,
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"input_value",
                         "value":"",
                         "display_name":"Text",
                         "advanced":false,
                         "input_types":[
                            "Message"
                         ],
                         "dynamic":false,
                         "info":"Text to be passed as output.",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"MultilineInput"
                      }
                   },
                   "description":"Display a text output in the Playground.",
                   "icon":"type",
                   "base_classes":[
                      "Message"
                   ],
                   "display_name":"Text Output",
                   "documentation":"",
                   "custom_fields":{
                      
                   },
                   "output_types":[
                      
                   ],
                   "pinned":false,
                   "conditional_paths":[
                      
                   ],
                   "frozen":false,
                   "outputs":[
                      {
                         "types":[
                            "Message"
                         ],
                         "selected":"Message",
                         "name":"text",
                         "display_name":"Text",
                         "method":"text_response",
                         "value":"__UNDEFINED__",
                         "cache":true
                      }
                   ],
                   "field_order":[
                      "input_value"
                   ],
                   "beta":false,
                   "legacy":false,
                   "edited":false,
                   "metadata":{
                      
                   },
                   "tool_mode":false,
                   "lf_version":"1.1.0"
                },
                "type":"TextOutput",
                "id":"TextOutput-C9FWZ"
             },
             "selected":false,
             "width":320,
             "height":233,
             "positionAbsolute":{
                "x":1258.3528285539594,
                "y":430.16605766087207
             },
             "dragging":false
          },
          {
             "id":"TextInput-gBxIv",
             "type":"genericNode",
             "position":{
                "x":-396.60345645310775,
                "y":283.84596872684284
             },
             "data":{
                "node":{
                   "template":{
                      "_type":"Component",
                      "code":{
                         "type":"code",
                         "required":true,
                         "placeholder":"",
                         "list":false,
                         "show":true,
                         "multiline":true,
                         "value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Scanned policy\"\n    description = \"Extracted document from webpage.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Policy agreement to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n",
                         "fileTypes":[
                            
                         ],
                         "file_path":"",
                         "password":false,
                         "name":"code",
                         "advanced":true,
                         "dynamic":true,
                         "info":"",
                         "load_from_db":false,
                         "title_case":false
                      },
                      "input_value":{
                         "tool_mode":false,
                         "trace_as_input":true,
                         "multiline":true,
                         "trace_as_metadata":true,
                         "load_from_db":false,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"input_value",
                         "value":"Privacy policy for the Pelico employer branding and recruitment Date of publication: 07-06-2024 We at Pelico manage our employer branding and recruitment process through our career site (the â€œCareer Siteâ€), and by using a related applicant tracking system. In this privacy policy, we explain how we process your personal data if: You visit our Career Site (you being a â€œVisitorâ€) You connect with us via our Career Site, to create a profile with us and receive information about current or future vacancies with us (you being a â€œConnecting Candidateâ€) You apply for a position with us, via our Career Site or a third party service (you being an â€Applying Candidateâ€) We collect information about you from other parties, sites and services, since we believe your profile is of interest for our current or future vacancies (you being a â€œSourced Candidateâ€) We receive information about you from our employees or partners, since they believe your profile is of interest for our current or future vacancies (you being a â€œReferred Candidateâ€) We receive information about you from a Candidate, who lists you as their reference (you being a â€œReferenceâ€). This privacy policy also describes what rights you have when we process your personal data, and how you can exercise these rights. When we use the term â€œCandidateâ€ in this privacy policy, we are referring to each of Connecting Candidates; Applying Candidates; Sourced Candidates; and Referred Candidates, unless itâ€™s stated otherwise. 1. About processing of personal data Personal data is all information that can be directly or indirectly linked to a living, physical person. Examples of personal data are: name, e-mail address, telephone number and IP address. Processing of personal data is any automated use of personal data - such as collecting, creating, analyzing, sharing, and deleting personal data. There are laws and regulations on how companies may process personal data, so-called data protection laws. Different data protection laws apply to different types of use of personal data, and in different parts of the world. An example of a data protection law that is relevant for our use of your personal data, as described in this privacy policy, is the EU Data Protection Regulation (2016/679, â€œGDPRâ€). Most obligations under the GDPR apply to the so-called data controller. A data controller is the entity that decides for which purposes personal data will be processed, and how the processing will be executed. The data controller can use a so-called data processor. A data processor is an entity that is only allowed to process personal data as instructed by the data controller, and may not use the personal data for its own purposes. We are the data controller when we process your personal data as described in this Privacy policy. 2. What personal data do we process? All individuals Device information - If you visit our Career Site, we will collect information about your device, such as IP address, browser type and version, session behaviour, traffic source, screen resolution, preferred language, geographic location, operating system and device settings/usage. Technical and statistical data - If you visit our Career Site, we will collect technical and statistical data about your use of the site, such as information about which URLs you visit, and your activity on the site. Communications data - We will collect and store your communication with us, including the information you provided in the communication. This may include the content of emails, video recordings, messages on social media, the information you add to your account with us, surveys, etc. Contact details - Such as your name, email address, telephone number and physical address. Candidates Data from interviews, assessments and other information from the recruitment process - Such as notes from interviews with you, assessments and tests made, salary requirements. Information in your application - Such as your CV, cover letter, work samples, references, letters of recommendation and education. Information in your public profile - Meaning the information we collect about you from public sources related to your professional experience, such as LinkedIn or the website of your current employer. Information provided by references - Meaning the information we receive from our employees or partners who refer you to us, or by the persons you have listed as your references. 3. Where do we receive your personal data from? All individuals From the Career Site. If you visit our Career Site, we collect technical and statistical information about how you use the Career Site, and information from your device. Directly from you. Most of the information we process about you, we receive directly from you, for example when you apply for a position with us or connect with us. You can always choose not to provide us with certain information. However, some personal data is necessary in order for us to process your application or provide you the information you request to get from us. References From the person for whom you are a reference. If a Candidate lists you as their reference, we will collect your contact details from the candidate to be able to contact you. Candidates From public sources. We may collect personal data about you from public sources, such as LinkedIn or the website of your current employer. From our references. We may receive information about you from our employees or partners (such as recruitment service providers), when they believe your profile is of interest for our current or future vacancies. From your references. If you provide us with references, we may collect information about you from them. Data we create ourselves or in cooperation with you. Information about your application and profile is usually created by us, or by us in cooperation with you, during the recruitment process. This may for example include notes from interviews with you, assessments and tests made. 4. For what purposes do we process your personal data? Protect and enforce our rights, interests and the interests of others, for example in connection with legal claims. Affected individuals: The individual(s) affected by the legal issue - this may include persons from all categories of individuals listed above. Categories of personal data used: All the categories of personal data listed above can be used for this purpose. Share your personal data with other recipients, for the purposes mentioned in Section 5 below. Affected individuals: Varies depending on the purpose of the sharing, see Section 5 below. Categories of personal data used: All the categories of personal data listed above may be used for this purpose. Collect information about your use of the Career Site, using cookies and other tracking technologies, as described in our Cookie Policy. Affected individuals: Visitors. Categories of personal data used: Device information. Maintain, develop, test, and otherwise ensure the security of the Career Site. Affected individuals: Visitors. Categories of personal data used: Device information; Technical and statistical data. Analyse how the Career Site and its content is being used and is performing, to get statistics and to improve operational performance. Affected individuals: Visitors. Categories of personal data used: Device information; Technical and statistical data. Provide you with updates about vacancies with us. Affected individuals: Connecting Candidates. Categories of personal data used: Contact details; Communications data. Review profiles and applications sent to us. This also includes communicating with you about your application and profile. Affected individuals: Connecting Candidates; Applying Candidates. Categories of personal data used: All the categories of personal data listed above may be used for this purpose. Collect and evaluate your professional profile on our own initiative. This also includes communicating with you regarding your profile. Affected individuals: Sourced Candidates; Referred Candidates. Categories of personal data used: All the categories of personal data listed above may be used for this purpose. Contact you directly about specific, future vacancies with us. Affected individuals: Candidates. Categories of personal data used: All the categories of personal data listed above may be used for this purpose. Record the interview(s) with you. Affected individuals: Candidates. Categories of personal data used: Communications data. Contact you to ask for your participation in surveys Affected individuals: Candidates. Categories of personal data used: All the categories of personal data listed above may be used for this purpose. Contact you to ask you to provide information about a Candidate, and evaluate the information you provide. Affected individuals: References. Categories of personal data used: Contact details; Communications data. 5. Whom do we share your personal data with? Our service providers. We share your personal data with our suppliers who provide services and functionality in our employer branding- and recruitment process. For example, this includes recruitment service providers and the supplier of our Career Site and related applicant tracking system. Our group companies. We share your personal data with our group companies, when they provide us services and functionality to our employer branding- and recruitment process, such as access to particular systems and software. Companies providing cookies on the Career Site. If you consent to it, cookies are set by other companies than us, who will use the data collected by these cookies in accordance with their own privacy policy. You can find information about which cookies this applies to in our Cookie Policy. To authorities and other public actors - when we are ordered to do so. We will share your personal data with authorities and other public actors when we have a legal obligation to do so. To parties involved in legal proceedings. If needed to protect or defend our rights, we share your personal data with public authorities or with other parties involved in a potential or existing legal proceeding. This can for example be in case of discrimination claims. Mergers and acquisitions etc. In connection with a potential merger, sale of company assets, financing, or acquisition of all or part of our business to another company, we may share your personal data to other parties involved in the process. 6. On what legal bases do we process your personal data? To be able to process your personal data, we need to have a so-called legal basis. A legal basis is a reason for processing the personal data that is justified under the GDPR. When we process your personal data for the purposes described in this Privacy Policy, the legal basis we rely on is normally that the processing is necessary for our legitimate interest in being able to recruit talent with the relevant competence for us. We have concluded that we have a legitimate interest in being able to perform the personal data processing for this purpose; that the processing is necessary to achieve that purpose; and that our interest outweighs your right not to have your data processed for this purpose. You can contact us for more information about how this assessment was made. See Section 9 and 10 below for our contact information. There may be specific circumstances when the processing is only performed if and when you provide your consent to the processing. This is for example the case if we propose to record an interview with you. Please see Section 9 below for more information about your right to withdraw your consent. 7. When do we transfer your personal data outside of the EU/EEA, and how do we protect it then? We always strive to process your personal data within the EU/EEA area. However, some of our service providers process your personal data outside of the EU/EEA. We also use suppliers whose parent company, or whose subcontractorâ€™s parent company, is based outside the EU/EEA. In these cases, we have taken into account the risk that the personal data may be disclosed to countries outside the EU/EEA, for example because of an authority request. In cases where another recipient of your personal data (as described in Section 5 above) is based outside the EU/EEA, this will also mean that your personal data is transferred outside the EU/EEA. When we, or one of our suppliers, transfer your personal data outside the EU/EEA, we will ensure that a safeguard recognized by the GDPR is used to enable the transfer. We use the following safeguards: A decision by the EU Commission that the country outside of the EU/EEA to which your personal data is transferred has an adequate level of protection, which corresponds to the level of protection afforded by the GDPR. In particular, we rely on the EU Commissionâ€™s adequacy decision for the US via the so-called EU-US Data Privacy Framework, and the adequacy decision for the UK. Entering into the EU Commissionâ€™s standard clauses with the recipient of the personal data outside the EU/EEA. This means that the recipient guarantees that the level of protection for your personal data afforded by the GDPR still applies, and that your rights are still protected. When your personal data is transferred outside the EU/EEA, we also implement appropriate technical and organizational safeguards, to protect the personal data in case of a disclosure. Exactly which protective measures we implement depends on what is technically feasible, and sufficiently effective, for the particular transfer. If you want more information about the cases in which your personal data is transferred outside the EU/EEA you can contact us using the contact details in Section 9 and 10 below. 8. For how long do we keep your personal data? All individuals If we process your personal data for the purpose of being able to protect and enforce our rights, we will keep your personal data until the relevant legal issue has been fully and finally resolved. Visitors We keep your personal data for one (1) year for security purposes. The retention periods for cookies are set out in our Cookie Policy. We keep your personal data to analyse the performance of the Career Site for as long as we keep personal data about you for other purposes. Candidates If you are a Connecting Candidate (only), we keep your personal data for as long as you remain connected with us. For other types of Candidates, we keep your personal data to decide if you are a suitable candidate for the relevant vacancy(ies) with us. If you donâ€™t succeed in the initial recruitment process, we keep your personal data for as long as needed to consider, and potentially contact you, for relevant future job openings. If you are hired, we will keep your personal data during your employment, for other purposes than those stated above, which you will be informed of. References We keep your personal data for as long as we keep the personal data of the Candidate for whom you acted as a reference. 9. What rights do you have, and how can you exercise them? In this section, you will find information about the rights you have when we process your personal data. As described below, some of the rights only come into play when we process your personal data under a particular legal basis. If you want to exercise any of the rights listed here, we suggest that you: Visit the Data & Privacy page on our Career Site, where we offer features to let you exercise your rights; Log in to your account with us, where you can use the settings in the account to exercise your rights; or Contact us directly at aleksandra.slimak@pelico.io. Right to be informed You have the right to be informed about how we process your personal data. You also have the right to be informed if we plan to process your personal data for any purpose other than that for which it was originally collected. We provide you with such information through this privacy policy, through updates on our Career Site (see also Section 11 below), and by answering any questions you may have for us. Right to access your personal data. You have the right to know if we process personal data about you, and to receive a copy of the data we process about you. In connection with receiving the copy of your data, you will also receive information about how we process your personal data. Right to access and to request a transfer of your personal data to another recipient (â€œdata portabilityâ€). You can request a copy of the personal data relating to you that we process for the performance of a contract with you, or based on your consent, in a structured, commonly used, machine-readable format. This will allow you to use this data somewhere else, for example to transfer it to another recipient. If technically feasible, you also have the right to request that we transfer your data directly to another recipient. Right to have your personal data deleted (â€œright to be forgottenâ€). In some cases, you have the right to have us delete personal data about you. This is for example the case if itâ€™s no longer necessary for us to process the data for the purpose for which we collected it; if you withdraw your consent; if you have objected to the processing and there are no legitimate, overriding justifications for the processing. (For the separate right to object, see below.) Right to object against our processing of your personal data. You have the right to object to processing of your personal data which is based on our legitimate interest, by referencing your personal circumstances. Right to restrict processing. If you believe that the personal data we process about you is inaccurate, that our processing is unlawful, or that we donâ€™t need the information for a specific purpose, you have the right to request that we restrict the processing of such personal data. If you object to our processing, as described just above, you can also request us to restrict processing of that personal data while we make our assessment of your request. When our processing of your personal data is restricted, we will (with the exception of storage) only process the data with your consent or for the establishment, exercise or defence of legal claims, to protect the rights of another natural or legal person, or for reasons relating to an important public interest. Right to rectification. You have the right to request that we rectify inaccurate information, and that we complete information about you that you consider incomplete. Right to withdraw your consent. When we process your personal data based on your consent, you have the right to withdraw that consent at any time. If you do so, we will stop processing your data for the purposes youâ€™ve withdrawn your consent for. However, it doesnâ€™t affect the lawfulness of processing that was based on your consent before it was withdrawn. Right to raise a complaint. If you have complaints about our processing of your personal data, you can raise a complaint with the data protection authority in France. You can find their contact details here. You can also lodge a complaint with your national data protection authority, which you can find listed here if you are based in the EU. If you are based in the UK, you can lodge a complaint with the Information Commissionerâ€™s Office, here. 10. Where can you turn with comments or questions? If you want to get in touch with us to exercise your rights, or if you have any questions, comments or concerns about how we handle your personal data, you can reach us by sending an email to aleksandra.slimak@pelico.io. 11. Updates to this Privacy policy We update this privacy policy when necessary - for example, because we start processing your personal data in a new way, because we want to make the information even clearer to you, or if itâ€™s necessary to do so in order to comply with applicable data protection laws. We encourage you to regularly check this page for any changes. You can always check the top of this page to see when this privacy policy was last updated.",
                         "display_name":"Text",
                         "advanced":false,
                         "input_types":[
                            "Message"
                         ],
                         "dynamic":false,
                         "info":"Policy agreement to be passed as input.",
                         "title_case":false,
                         "type":"str",
                         "_input_type":"MultilineInput"
                      }
                   },
                   "description":"Extracted document from webpage.",
                   "icon":"type",
                   "base_classes":[
                      "Message"
                   ],
                   "display_name":"Scanned Policy ",
                   "documentation":"",
                   "custom_fields":{
                      
                   },
                   "output_types":[
                      
                   ],
                   "pinned":false,
                   "conditional_paths":[
                      
                   ],
                   "frozen":false,
                   "outputs":[
                      {
                         "types":[
                            "Message"
                         ],
                         "selected":"Message",
                         "name":"text",
                         "display_name":"Text",
                         "method":"text_response",
                         "value":"__UNDEFINED__",
                         "cache":true
                      }
                   ],
                   "field_order":[
                      "input_value"
                   ],
                   "beta":false,
                   "legacy":false,
                   "edited":true,
                   "metadata":{
                      
                   },
                   "tool_mode":false,
                   "lf_version":"1.1.0"
                },
                "type":"TextInput",
                "id":"TextInput-gBxIv"
             },
             "selected":true,
             "width":320,
             "height":233,
             "positionAbsolute":{
                "x":-396.60345645310775,
                "y":283.84596872684284
             },
             "dragging":false
          },
          {
             "id":"Prompt-Ur8mM",
             "type":"genericNode",
             "position":{
                "x":-8.849637410582318,
                "y":448.1720763182876
             },
             "data":{
                "description":"Create a prompt template with dynamic variables.",
                "display_name":"Prompt",
                "id":"Prompt-Ur8mM",
                "node":{
                   "template":{
                      "_type":"Component",
                      "code":{
                         "type":"code",
                         "required":true,
                         "placeholder":"",
                         "list":false,
                         "show":true,
                         "multiline":true,
                         "value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Eqip AI as a legal expert\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                         "fileTypes":[
                            
                         ],
                         "file_path":"",
                         "password":false,
                         "name":"code",
                         "advanced":true,
                         "dynamic":true,
                         "info":"",
                         "load_from_db":false,
                         "title_case":false
                      },
                      "template":{
                         "tool_mode":false,
                         "trace_as_input":true,
                         "list":false,
                         "required":false,
                         "placeholder":"",
                         "show":true,
                         "name":"template",
                         "value":"<instructions>\nPlay the role of a legal expert on privacy policy and terms and conditions. Your task is to read a privacy policy document, or the terms and conditions document given to you and look out for harmful discrepancies in the document.\n\nHere is the document to be read,\n\n<extracted_document>\n{EXTRACTED_DOCUMENT}\n</extracted_document>\n\nState at most 3 most shady discrepancies found in the document as bullet points with - for bullet. \n\nRemember to\n-Make each point no more than 15 words.\n-Get straight to the point.\n-Use English that an 18-year-old can understand.\n</instructions>",
                         "display_name":"Template",
                         "advanced":false,
                         "dynamic":false,
                         "info":"",
                         "title_case":false,
                         "type":"prompt",
                         "_input_type":"PromptInput",
                         "load_from_db":false
                      },
                      "EXTRACTED_DOCUMENT":{
                         "field_type":"str",
                         "required":false,
                         "placeholder":"",
                         "list":false,
                         "show":true,
                         "multiline":true,
                         "value":"",
                         "fileTypes":[
                            
                         ],
                         "file_path":"",
                         "name":"EXTRACTED_DOCUMENT",
                         "display_name":"EXTRACTED_DOCUMENT",
                         "advanced":false,
                         "input_types":[
                            "Message",
                            "Text"
                         ],
                         "dynamic":false,
                         "info":"",
                         "load_from_db":false,
                         "title_case":false,
                         "type":"str"
                      }
                   },
                   "description":"Eqip AI as a legal expert",
                   "icon":"prompts",
                   "is_input":null,
                   "is_output":null,
                   "is_composition":null,
                   "base_classes":[
                      "Message"
                   ],
                   "name":"",
                   "display_name":"Legal agent prompt",
                   "documentation":"",
                   "custom_fields":{
                      "template":[
                         "EXTRACTED_DOCUMENT"
                      ]
                   },
                   "output_types":[
                      
                   ],
                   "full_path":null,
                   "pinned":false,
                   "conditional_paths":[
                      
                   ],
                   "frozen":false,
                   "outputs":[
                      {
                         "types":[
                            "Message"
                         ],
                         "selected":"Message",
                         "name":"prompt",
                         "hidden":null,
                         "display_name":"Prompt Message",
                         "method":"build_prompt",
                         "value":"__UNDEFINED__",
                         "cache":true,
                         "required_inputs":null
                      }
                   ],
                   "field_order":[
                      "template"
                   ],
                   "beta":false,
                   "legacy":false,
                   "error":null,
                   "edited":true,
                   "metadata":{
                      
                   },
                   "tool_mode":false,
                   "lf_version":"1.1.0"
                },
                "type":"Prompt"
             },
             "selected":false,
             "width":320,
             "height":326,
             "positionAbsolute":{
                "x":-8.849637410582318,
                "y":448.1720763182876
             },
             "dragging":false
          }
       ],
       "edges":[
          {
             "source":"OllamaModel-kmzJQ",
             "sourceHandle":"{Å“dataTypeÅ“:Å“OllamaModelÅ“,Å“idÅ“:Å“OllamaModel-kmzJQÅ“,Å“nameÅ“:Å“text_outputÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
             "target":"CustomComponent-Kwa0O",
             "targetHandle":"{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“CustomComponent-Kwa0OÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
             "data":{
                "targetHandle":{
                   "fieldName":"input_value",
                   "id":"CustomComponent-Kwa0O",
                   "inputTypes":[
                      "Message"
                   ],
                   "type":"str"
                },
                "sourceHandle":{
                   "dataType":"OllamaModel",
                   "id":"OllamaModel-kmzJQ",
                   "name":"text_output",
                   "output_types":[
                      "Message"
                   ]
                }
             },
             "id":"reactflow__edge-OllamaModel-kmzJQ{Å“dataTypeÅ“:Å“OllamaModelÅ“,Å“idÅ“:Å“OllamaModel-kmzJQÅ“,Å“nameÅ“:Å“text_outputÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-CustomComponent-Kwa0O{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“CustomComponent-Kwa0OÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
             "animated":false,
             "className":""
          },
          {
             "source":"CustomComponent-Kwa0O",
             "sourceHandle":"{Å“dataTypeÅ“:Å“jsonParserÅ“,Å“idÅ“:Å“CustomComponent-Kwa0OÅ“,Å“nameÅ“:Å“outputÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
             "target":"ChatOutput-2w5Rb",
             "targetHandle":"{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ChatOutput-2w5RbÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
             "data":{
                "targetHandle":{
                   "fieldName":"input_value",
                   "id":"ChatOutput-2w5Rb",
                   "inputTypes":[
                      "Message"
                   ],
                   "type":"str"
                },
                "sourceHandle":{
                   "dataType":"jsonParser",
                   "id":"CustomComponent-Kwa0O",
                   "name":"output",
                   "output_types":[
                      "Message"
                   ]
                }
             },
             "id":"reactflow__edge-CustomComponent-Kwa0O{Å“dataTypeÅ“:Å“jsonParserÅ“,Å“idÅ“:Å“CustomComponent-Kwa0OÅ“,Å“nameÅ“:Å“outputÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-ChatOutput-2w5Rb{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ChatOutput-2w5RbÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
             "animated":false,
             "className":""
          },
          {
             "source":"CustomComponent-Kwa0O",
             "sourceHandle":"{Å“dataTypeÅ“:Å“jsonParserÅ“,Å“idÅ“:Å“CustomComponent-Kwa0OÅ“,Å“nameÅ“:Å“outputÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
             "target":"TextOutput-C9FWZ",
             "targetHandle":"{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“TextOutput-C9FWZÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
             "data":{
                "targetHandle":{
                   "fieldName":"input_value",
                   "id":"TextOutput-C9FWZ",
                   "inputTypes":[
                      "Message"
                   ],
                   "type":"str"
                },
                "sourceHandle":{
                   "dataType":"jsonParser",
                   "id":"CustomComponent-Kwa0O",
                   "name":"output",
                   "output_types":[
                      "Message"
                   ]
                }
             },
             "id":"reactflow__edge-CustomComponent-Kwa0O{Å“dataTypeÅ“:Å“jsonParserÅ“,Å“idÅ“:Å“CustomComponent-Kwa0OÅ“,Å“nameÅ“:Å“outputÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-TextOutput-C9FWZ{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“TextOutput-C9FWZÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
             "className":"",
             "animated":false
          },
          {
             "source":"Prompt-Ur8mM",
             "sourceHandle":"{Å“dataTypeÅ“:Å“PromptÅ“,Å“idÅ“:Å“Prompt-Ur8mMÅ“,Å“nameÅ“:Å“promptÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
             "target":"OllamaModel-kmzJQ",
             "targetHandle":"{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“OllamaModel-kmzJQÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
             "data":{
                "targetHandle":{
                   "fieldName":"input_value",
                   "id":"OllamaModel-kmzJQ",
                   "inputTypes":[
                      "Message"
                   ],
                   "type":"str"
                },
                "sourceHandle":{
                   "dataType":"Prompt",
                   "id":"Prompt-Ur8mM",
                   "name":"prompt",
                   "output_types":[
                      "Message"
                   ]
                }
             },
             "id":"reactflow__edge-Prompt-Ur8mM{Å“dataTypeÅ“:Å“PromptÅ“,Å“idÅ“:Å“Prompt-Ur8mMÅ“,Å“nameÅ“:Å“promptÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-OllamaModel-kmzJQ{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“OllamaModel-kmzJQÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
             "animated":false,
             "className":""
          },
          {
             "source":"TextInput-gBxIv",
             "sourceHandle":"{Å“dataTypeÅ“:Å“TextInputÅ“,Å“idÅ“:Å“TextInput-gBxIvÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
             "target":"Prompt-Ur8mM",
             "targetHandle":"{Å“fieldNameÅ“:Å“EXTRACTED_DOCUMENTÅ“,Å“idÅ“:Å“Prompt-Ur8mMÅ“,Å“inputTypesÅ“:[Å“MessageÅ“,Å“TextÅ“],Å“typeÅ“:Å“strÅ“}",
             "data":{
                "targetHandle":{
                   "fieldName":"EXTRACTED_DOCUMENT",
                   "id":"Prompt-Ur8mM",
                   "inputTypes":[
                      "Message",
                      "Text"
                   ],
                   "type":"str"
                },
                "sourceHandle":{
                   "dataType":"TextInput",
                   "id":"TextInput-gBxIv",
                   "name":"text",
                   "output_types":[
                      "Message"
                   ]
                }
             },
             "id":"reactflow__edge-TextInput-gBxIv{Å“dataTypeÅ“:Å“TextInputÅ“,Å“idÅ“:Å“TextInput-gBxIvÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-Prompt-Ur8mM{Å“fieldNameÅ“:Å“EXTRACTED_DOCUMENTÅ“,Å“idÅ“:Å“Prompt-Ur8mMÅ“,Å“inputTypesÅ“:[Å“MessageÅ“,Å“TextÅ“],Å“typeÅ“:Å“strÅ“}",
             "animated":false,
             "className":""
          }
       ],
       "viewport":{
          "x":284.56251758398577,
          "y":149.76073685278007,
          "zoom":0.5744661100391873
       }
    },
    "updated_at":"2025-03-17T09:07:51+00:00",
    "icon_bg_color":null,
    "icon":null
 }